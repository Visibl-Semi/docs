---
title: "Get Started"
description: "Install Visibl's local AI infrastructure for silicon engineering"
---

Visibl provides local AI infrastructure for silicon engineering teams. Install the LLM service once on your server (set it and forget it), then install the CLI on your workstations to start working.

<Frame>
  <img src="/assets/cli.png" alt="Visibl architecture: LLM service running on GPU server, CLI connecting from workstations" />
</Frame>

## Install LLM Service

Deploy the AI infrastructure on your server:

```bash
curl -fsSL https://visiblsemi.com/api/install-llm | sudo bash
```

This installs the service with GPU support and starts it on port 58180.

**Verify installation:**
```bash
visibl-smi
```

You should see your GPU(s) listed with the running Visibl LLM service.

## Install CLI

Install the CLI on your development workstation:

```bash
curl -fsSL https://visiblsemi.com/api/install | bash
```

The CLI automatically discovers and connects to your local LLM service.

**Launch the CLI:**
```bash
visibl
```

This opens the interactive TUI where you can chat with the AI about your silicon engineering tasks.

## Start Using Visibl

Initialize your project for context-aware assistance:

```bash
cd your-rtl-project/
visibl init  # Creates AGENTS.md with build flows, EDA tools, coding standards
```

Launch the TUI and start working:

```bash
visibl
```

```
> Create a safe multi-bit clock domain crossing circuit using gray code
> Generate SystemVerilog assertions for AXI4 handshake protocol validation
> Help me debug this timing violation in my memory controller
```

## Doc Agent

Generate comprehensive documentation for your RTL modules:

**Interactive TUI:**
```bash
visibl
/docs uart_core
```

**Headless CLI:**
```bash
visibl docs uart_core
```

See the [Doc Agent guide](/cli/doc-gen) for details.

## Troubleshooting

<AccordionGroup>
  <Accordion title="LLM service won't start">
    Send us the following for support:
    
    1. Service logs:
    ```bash
    visibl-llm logs -f
    ```
    
    2. Screenshot of:
    ```bash
    visibl-smi
    ```
    
    3. Description of the issue
    
    Email everything to [hi@visiblsemi.com](mailto:hi@visiblsemi.com)
  </Accordion>
  
  <Accordion title="CLI can't connect to service">
    Send us the output when you try to run:
    ```bash
    visibl
    ```
    
    The CLI has automatic binding logic that connects to the running LLM service. If it fails, the output will show us what went wrong.
    
    Email the output and description to [hi@visiblsemi.com](mailto:hi@visiblsemi.com)
  </Accordion>
  
  <Accordion title="Need help?">
    Email [hi@visiblsemi.com](mailto:hi@visiblsemi.com) with:
    
    - Output from `visibl-llm logs -f`
    - Screenshot from `visibl-smi`
    - Output from running `visibl`
    - Description of the issue
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="CLI Examples" icon="code" href="/cli/examples">
    See practical examples for RTL design and verification
  </Card>
  
  <Card title="LLM Service" icon="server" href="/llm-service/overview">
    Learn about the local AI infrastructure
  </Card>
  
  <Card title="Doc Agent" icon="file-text" href="/cli/doc-gen">
    Generate comprehensive RTL documentation
  </Card>
  
  <Card title="CLI Overview" icon="terminal" href="/cli/overview">
    Explore all CLI capabilities
  </Card>
</CardGroup>
